{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.executable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get the current working directory\n",
    "current_folder = os.getcwd()\n",
    "relative_path = '../RawData/2000_to_2024.xlsx'\n",
    "full_path = os.path.join(current_folder, relative_path)\n",
    "# get raw data from excel file\n",
    "df = pd.read_excel(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Preprocessing\n",
    "# 1. Drop signals with is_closed = False\n",
    "df = df[df['is_closed'] == True]\n",
    "# 2. Drop signals with same signal_time\n",
    "df = df.drop_duplicates(subset=['signal_time'])\n",
    "# 3. Normalize rsi_value due to trend_type : if trend_type = -1 then rsi_value = 100 - rsi_value\n",
    "df['rsi_value'] = df.apply(lambda x: 100 - x['rsi_value'] if x['trend_type'] == -1 else x['rsi_value'], axis=1)\n",
    "# 4. Drop columns that are not needed including 'is_closed', 'trend_type', 'signal_time', 'signal_price',\n",
    "# 'tp_1_hit', 'tp_2_hit', 'tp_3_hit', 'tp_4_hit', 'tp_5_hit', 'tp_6_hit', 'tp_7_hit', 'tp_8_hit', \n",
    "# last_stop_tp_1_number, last_stop_tp_2_number, last_stop_tp_3_number, last_stop_tp_4_number, last_stop_tp_5_number,\n",
    "# last_stop_tp_6_number, last_stop_tp_7_number, last_stop_tp_8_number, rd_filter_passed , hd_filter_passed\n",
    "df = df.drop(columns=['max_price_move','pair_name','max_seen_value','min_seen_value','sl_2_hit','sl_1_hit', 'is_closed', 'trend_type', 'signal_time', 'signal_price', 'tp_1_hit', 'tp_2_hit', 'tp_3_hit', 'tp_4_hit', 'tp_5_hit', 'tp_6_hit', 'tp_7_hit', 'tp_8_hit', 'last_stop_tp_1_number', 'last_stop_tp_2_number', 'last_stop_tp_3_number', 'last_stop_tp_4_number', 'last_stop_tp_5_number', 'last_stop_tp_6_number', 'last_stop_tp_7_number', 'last_stop_tp_8_number', 'rd_filter_passed', 'hd_filter_passed'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create init data file \n",
    "# Save DataFrame as CSV\n",
    "df.to_csv('processed_data_init.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "data = pd.read_csv('processed_data_init.csv')\n",
    "\n",
    "# Convert boolean columns to int for consistency\n",
    "data['is_big_fractal_resistance'] = data['is_big_fractal_resistance'].astype(int)\n",
    "data['rsi_filter_passed'] = data['rsi_filter_passed'].astype(int)\n",
    "\n",
    "# Visualize correlations\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(data.corr(), annot=True, cmap=\"coolwarm\", fmt=\".2f\", linewidths=0.5)\n",
    "plt.title(\"Correlation Matrix of Features\")\n",
    "plt.show()\n",
    "\n",
    "# Define features and targets\n",
    "X = data.drop(['last_tp_sl_1_number', 'last_tp_sl_2_number'], axis=1)\n",
    "y1 = data['last_tp_sl_1_number']\n",
    "y2 = data['last_tp_sl_2_number']\n",
    "\n",
    "# Convert targets to categorical\n",
    "y1 = to_categorical(y1 + 1)  # shift by 1 for range -1 to 8\n",
    "y2 = to_categorical(y2 + 1)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y1_train, y1_test, y2_train, y2_test = train_test_split(X, y1, y2, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Define model architecture\n",
    "input_layer = Input(shape=(X_train.shape[1],))\n",
    "hidden_layer_1 = Dense(64, activation='relu')(input_layer)\n",
    "dropout_1 = Dropout(0.3)(hidden_layer_1)\n",
    "hidden_layer_2 = Dense(32, activation='relu')(dropout_1)\n",
    "dropout_2 = Dropout(0.3)(hidden_layer_2)\n",
    "\n",
    "# Separate outputs for two targets\n",
    "output1 = Dense(y1.shape[1], activation='softmax', name=\"output_1\")(dropout_2)\n",
    "output2 = Dense(y2.shape[1], activation='softmax', name=\"output_2\")(dropout_2)\n",
    "\n",
    "# Compile model\n",
    "model = Model(inputs=input_layer, outputs=[output1, output2])\n",
    "model.compile(optimizer='adam', \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Display model summary\n",
    "model.summary()\n",
    "\n",
    "# Callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, [y1_train, y2_train],\n",
    "                    validation_data=(X_test, [y1_test, y2_test]),\n",
    "                    epochs=100,\n",
    "                    batch_size=32,\n",
    "                    callbacks=[early_stopping])\n",
    "\n",
    "# Plot training history\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# Loss plot\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title(\"Model Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "\n",
    "# Accuracy plot\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['output_1_accuracy'], label='Output 1 Training Accuracy')\n",
    "plt.plot(history.history['val_output_1_accuracy'], label='Output 1 Validation Accuracy')\n",
    "plt.plot(history.history['output_2_accuracy'], label='Output 2 Training Accuracy')\n",
    "plt.plot(history.history['val_output_2_accuracy'], label='Output 2 Validation Accuracy')\n",
    "plt.title(\"Model Accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Predictions\n",
    "y1_pred, y2_pred = model.predict(X_test)\n",
    "y1_pred_classes = np.argmax(y1_pred, axis=1) - 1\n",
    "y2_pred_classes = np.argmax(y2_pred, axis=1) - 1\n",
    "\n",
    "# Convert y1_test and y2_test to original classes for comparison\n",
    "y1_test_classes = np.argmax(y1_test, axis=1) - 1\n",
    "y2_test_classes = np.argmax(y2_test, axis=1) - 1\n",
    "\n",
    "# Classification report and confusion matrix for both outputs\n",
    "print(\"Classification Report for last_tp_sl_1_number:\")\n",
    "print(classification_report(y1_test_classes, y1_pred_classes))\n",
    "print(\"Confusion Matrix for last_tp_sl_1_number:\")\n",
    "print(confusion_matrix(y1_test_classes, y1_pred_classes))\n",
    "\n",
    "print(\"\\nClassification Report for last_tp_sl_2_number:\")\n",
    "print(classification_report(y2_test_classes, y2_pred_classes))\n",
    "print(\"Confusion Matrix for last_tp_sl_2_number:\")\n",
    "print(confusion_matrix(y2_test_classes, y2_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
